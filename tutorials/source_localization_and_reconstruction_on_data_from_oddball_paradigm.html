
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Source localization and signal reconstruction - case study for oddball data &#8212; mvpure_py 1.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=d6b6a36a"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/source_localization_and_reconstruction_on_data_from_oddball_paradigm';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="EEG Preprocessing for an Oddball Paradigm" href="preprocessing_data_from_oddball%20paradigm.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt=""/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">mvpure_py</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
        <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Source localization and signal reconstruction - case study for oddball data</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <style>
/* Make all output cells scrollable if they are tall */
div.nboutput:not(:has(div.figure)) {
    max-height: 380px;
    overflow-y: auto;
    padding: 2px;
}
</style><p>Author: Julia Jurkowska</p>
<section id="Source-localization-and-signal-reconstruction---case-study-for-oddball-data">
<h1>Source localization and signal reconstruction - case study for oddball data<a class="headerlink" href="#Source-localization-and-signal-reconstruction---case-study-for-oddball-data" title="Link to this heading">#</a></h1>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading">#</a></h2>
<p>In this tutorial, we will learn how to <strong>localize sources</strong> from EEG data and <strong>reconstruct signals</strong> at those sources using <strong>MVPURE-py</strong>, an extension to MNE-Python. Source localization allows us to move beyond sensor-level analysis to estimate where in the brain the measured activity originates. Once sources are identified, we can reconstruct time series from vertices of interest for further analysis.</p>
<p>We will cover the following steps:</p>
<ol class="arabic simple">
<li><p>Reading all necessary data for the <code class="docutils literal notranslate"><span class="pre">sample_subject</span></code>. You can download this dataset <a class="reference external" href="https://figshare.com/articles/dataset/Sample_subject_data_/30102451?file=57853861">here</a>.</p></li>
<li><p>Computing data and noise covariance (R and N, respectively).</p></li>
<li><p>Analysis of <span class="math notranslate nohighlight">\(RN^{-1}\)</span> eigenvalues to guide the number of sources to localize and select an appropriate optimization parameter.</p></li>
<li><p>Localizing the specified number of sources.</p></li>
<li><p>Reconstructing source signals for vertices of interest and plotting the results.</p></li>
</ol>
<p>All steps will be repeated for two time frames: “sensory” (50-200 ms after stimuli) and “cognitive” (350-600 ms after stimuli).</p>
<p>By the end of this tutorial, you will understand the basic workflow of source localization and signal reconstruction using the MVPURE-py package.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mne</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">set_3d_backend</span><span class="p">(</span><span class="s1">&#39;pyvistaqt&#39;</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">mvpure_py</span><span class="w"> </span><span class="kn">import</span> <span class="n">localizer</span><span class="p">,</span> <span class="n">beamformer</span><span class="p">,</span> <span class="n">viz</span><span class="p">,</span> <span class="n">utils</span>
</pre></div>
</div>
</div>
<p>We will use data the <code class="docutils literal notranslate"><span class="pre">sample_subject</span></code> dataset <a class="reference external" href="https://figshare.com/articles/dataset/Sample_subject_data_/30102451?file=57853861">provided on Figshare</a>. If you wish to start from the beginning, please complete tutorial [Preprocessing data from oddball paradigm] first.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;sample_subject&quot;</span>
<span class="n">subjects_dir</span> <span class="o">=</span> <span class="s2">&quot;subjects&quot;</span>

<span class="c1"># Reading mne.Epochs</span>
<span class="n">epoched</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">read_epochs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subjects_dir</span><span class="p">,</span> <span class="n">subject</span><span class="p">,</span> <span class="s2">&quot;_eeg&quot;</span><span class="p">,</span> <span class="s2">&quot;_pre&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_oddball-epo.fif&quot;</span><span class="p">))</span>
<span class="n">forward_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subjects_dir</span><span class="p">,</span> <span class="n">subject</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_ico4-fwd.fif&quot;</span><span class="p">)</span>
<span class="n">trans_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subjects_dir</span><span class="p">,</span> <span class="n">subject</span><span class="p">,</span> <span class="s2">&quot;_eeg&quot;</span><span class="p">,</span> <span class="s2">&quot;trans&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">-fit_trans.fif&quot;</span><span class="p">)</span>

<span class="c1"># We will be using only data for &#39;target&#39; stimuli</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">epoched</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">sel_epoched</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">sel_epoched</span> <span class="o">=</span> <span class="n">sel_epoched</span><span class="o">.</span><span class="n">set_eeg_reference</span><span class="p">(</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sel_epoched</span><span class="o">.</span><span class="n">apply_proj</span><span class="p">()</span>
<span class="n">sel_evoked</span> <span class="o">=</span> <span class="n">sel_epoched</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reading /Volumes/UMK/oddball/subjects/sample_subject/_eeg/_pre/sample_subject_oddball-epo.fif ...
    Found the data of interest:
        t =    -199.22 ...     800.78 ms
        0 CTF compensation matrices available
Not setting metadata
621 matching events found
No baseline correction applied
0 projection items activated
EEG channel type selected for re-referencing
Adding average EEG reference projection.
1 projection items deactivated
Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.
Created an SSP operator (subspace dimension = 1)
1 projection items activated
SSP projectors applied...
</pre></div></div>
</div>
<p>To perform source localization, we need a <strong>forward model</strong> that links activity at source locations to the sensors (in this case EEG channels). Here, we load the forward solution and convert it to a fixed-orientation representation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reading mne.Forward</span>
<span class="n">fwd_vector</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">read_forward_solution</span><span class="p">(</span><span class="n">forward_path</span><span class="p">)</span>

<span class="c1"># Using fixed orientation in forward solution</span>
<span class="n">fwd</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">convert_forward_solution</span><span class="p">(</span>
    <span class="n">fwd_vector</span><span class="p">,</span>
    <span class="n">surf_ori</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">force_fixed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">use_cps</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Leadfield matrix</span>
<span class="n">leadfield</span> <span class="o">=</span> <span class="n">fwd</span><span class="p">[</span><span class="s2">&quot;sol&quot;</span><span class="p">][</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>

<span class="c1"># Source positions extracted from forward model</span>
<span class="n">src</span> <span class="o">=</span> <span class="n">fwd</span><span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reading forward solution from /Volumes/UMK/oddball/subjects/sample_subject/forward/sample_subject_ico4-fwd.fif...
    Reading a source space...
    [done]
    Reading a source space...
    [done]
    2 source spaces read
    Desired named matrix (kind = 3523 (FIFF_MNE_FORWARD_SOLUTION_GRAD)) not available
    Read EEG forward solution (5124 sources, 128 channels, free orientations)
    Source spaces transformed to the forward solution coordinate frame
    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....
    Changing to fixed-orientation forward solution with surface-based source orientations...
    [done]
</pre></div></div>
</div>
</section>
<section id="%22Sensory%22-processing">
<h2>“Sensory” processing<a class="headerlink" href="#%22Sensory%22-processing" title="Link to this heading">#</a></h2>
<p>We will start with analysing processes in “sensory” time window.</p>
<p>In an oddball paradigm, participants are presented with a sequence of frequent (standard) and infrequent (target) stimuli. The early neural responses to these target stimuli reflect <strong>sensory processing</strong> - the brain’s initial registration of the incoming stimulus before higher-level cognitive mechanisms are engaged. We assume that sensory processing for given oddball paradigm occurs within the <strong>50-200 ms</strong> window after the stimuli. We will therefore compute the data covariance in this time
range. To estimate the noise covariance, we use a baseline period <strong>-200ms to 0 ms</strong>, i.e., the interval before stimulus onset. This baseline is assumed to be free of stimulus-locked activity and provides reference for separating signal from noise.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute noise covariance</span>
<span class="n">noise_cov</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span>
    <span class="n">sel_epoched</span><span class="p">,</span>
    <span class="n">tmin</span><span class="o">=-</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;empirical&quot;</span>
<span class="p">)</span>

<span class="c1"># Compute data covariance for range corresponding to sensory processing</span>
<span class="n">data_cov_sen</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span>
    <span class="n">sel_epoched</span><span class="p">,</span>
    <span class="n">tmin</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;empirical&quot;</span>
<span class="p">)</span>

<span class="c1"># Subset signal for given time range</span>
<span class="n">signal_sen</span> <span class="o">=</span> <span class="n">sel_evoked</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span>
    <span class="n">tmin</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mf">0.2</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
    Created an SSP operator (subspace dimension = 1)
    Setting small EEG eigenvalues to zero (without PCA)
Reducing data rank from 128 -&gt; 127
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 4056
[done]
    Created an SSP operator (subspace dimension = 1)
    Setting small EEG eigenvalues to zero (without PCA)
Reducing data rank from 128 -&gt; 127
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 3042
[done]
</pre></div></div>
</div>
<section id="RN^{-1}-eigenvalues-analysis">
<h3><span class="math notranslate nohighlight">\(RN^{-1}\)</span> eigenvalues analysis<a class="headerlink" href="#RN^{-1}-eigenvalues-analysis" title="Link to this heading">#</a></h3>
<p>Before attempting source localization, we need to decide <strong>how many sources</strong> to model and with what <strong>rank</strong>. Our proposition is to analyze the eigenvalues of the product of data covariance matrix <span class="math notranslate nohighlight">\(R\)</span> and the inverse of the noise covariance matrix <span class="math notranslate nohighlight">\(N\)</span>. For a detailed theoretical background, see [PAPER].</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sugg_n_sources</span><span class="p">,</span> <span class="n">sugg_rank</span> <span class="o">=</span> <span class="n">localizer</span><span class="o">.</span><span class="n">suggest_n_sources_and_rank</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span><span class="n">data_cov_sen</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">N</span><span class="o">=</span><span class="n">noise_cov</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">show_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">14</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_source_localization_and_reconstruction_on_data_from_oddball_paradigm_11_0.png" src="../_images/tutorials_source_localization_and_reconstruction_on_data_from_oddball_paradigm_11_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Suggested number of sources to localize: 62
Suggested rank is: 42
</pre></div></div>
</div>
</section>
<section id="Localize">
<h3>Localize<a class="headerlink" href="#Localize" title="Link to this heading">#</a></h3>
<p>Based on the eigenvalue spectrium above, we will localize <strong>62 sources</strong> using <strong>rank of 42</strong>. We will use function <code class="docutils literal notranslate"><span class="pre">mvpure_py.localizer.localize</span></code>, which performs the actual source localization. The main parameters are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">subject</span></code>: the subject ID (here: <code class="docutils literal notranslate"><span class="pre">&quot;sample_subject&quot;</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">subjects_dir</span></code>: directory containing the subject folders.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">localizer_to_use</span></code>: the algorithm variant. Here we choose <code class="docutils literal notranslate"><span class="pre">&quot;mpz_mvp&quot;</span></code> because it provides the highest spacial resolution. Other possible options include: <code class="docutils literal notranslate"><span class="pre">&quot;mai&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;mpz&quot;</span></code>, and <code class="docutils literal notranslate"><span class="pre">&quot;mai_mvp&quot;</span></code>. For details, see [PAPER] or the function documentation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_sources_to_localize</span></code>: number of sources to localize. We will use the suggested number of sources from <span class="math notranslate nohighlight">\(RN^{-1}\)</span> analysis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">R</span></code>: data covariance matrix</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">N</span></code>: noise covariance matrix</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>: the <code class="docutils literal notranslate"><span class="pre">mne.Forward</span></code> object for this subject</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">r</span></code>: optimization rank parameter. We use the suggested value from the eigenvalues analysis, but it can be any integer smaller than <code class="docutils literal notranslate"><span class="pre">number_of_sources_to_localize</span></code>.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">locs_sen</span> <span class="o">=</span> <span class="n">localizer</span><span class="o">.</span><span class="n">localize</span><span class="p">(</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">subjects_dir</span><span class="o">=</span><span class="n">subjects_dir</span><span class="p">,</span>
    <span class="n">localizer_to_use</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mpz_mvp&quot;</span><span class="p">],</span>
    <span class="n">n_sources_to_localize</span><span class="o">=</span><span class="n">sugg_n_sources</span><span class="p">,</span>
    <span class="n">R</span><span class="o">=</span><span class="n">data_cov_sen</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">N</span><span class="o">=</span><span class="n">noise_cov</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">forward</span><span class="o">=</span><span class="n">fwd</span><span class="p">,</span>
    <span class="n">r</span><span class="o">=</span><span class="n">sugg_rank</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-cyan-fg">Calculating activity index for localizer: mpz_mvp</span>
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 5124/5124 [00:16&lt;00:00, 302.37it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 311.68it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 311.65it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 306.47it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 309.97it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 307.57it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 303.06it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 304.61it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 303.29it/s]
100%|██████████| 5124/5124 [00:16&lt;00:00, 302.00it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 301.35it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 295.38it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 294.21it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 295.95it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 293.16it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 291.34it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 282.57it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 287.68it/s]
100%|██████████| 5124/5124 [00:17&lt;00:00, 285.50it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 269.37it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 268.82it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 272.12it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 275.31it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 278.55it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 274.03it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 277.67it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 272.22it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 272.04it/s]
100%|██████████| 5124/5124 [00:18&lt;00:00, 271.20it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 266.81it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 266.88it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 264.43it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 264.33it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 264.21it/s]
100%|██████████| 5124/5124 [00:19&lt;00:00, 260.33it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 231.19it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 226.51it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 230.34it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 231.64it/s]
100%|██████████| 5124/5124 [00:23&lt;00:00, 215.33it/s]
100%|██████████| 5124/5124 [00:30&lt;00:00, 168.64it/s]
100%|██████████| 5124/5124 [00:28&lt;00:00, 181.66it/s]
100%|██████████| 5124/5124 [00:33&lt;00:00, 152.17it/s]
100%|██████████| 5124/5124 [00:34&lt;00:00, 146.65it/s]
100%|██████████| 5124/5124 [00:36&lt;00:00, 141.51it/s]
100%|██████████| 5124/5124 [00:38&lt;00:00, 131.63it/s]
100%|██████████| 5124/5124 [00:39&lt;00:00, 129.57it/s]
100%|██████████| 5124/5124 [00:36&lt;00:00, 139.15it/s]
100%|██████████| 5124/5124 [00:38&lt;00:00, 133.81it/s]
100%|██████████| 5124/5124 [00:38&lt;00:00, 134.63it/s]
100%|██████████| 5124/5124 [00:38&lt;00:00, 133.06it/s]
100%|██████████| 5124/5124 [00:39&lt;00:00, 128.37it/s]
100%|██████████| 5124/5124 [00:37&lt;00:00, 136.43it/s]
100%|██████████| 5124/5124 [00:37&lt;00:00, 137.27it/s]
100%|██████████| 5124/5124 [00:37&lt;00:00, 136.45it/s]
100%|██████████| 5124/5124 [00:38&lt;00:00, 132.86it/s]
100%|██████████| 5124/5124 [00:39&lt;00:00, 129.94it/s]
100%|██████████| 5124/5124 [00:39&lt;00:00, 128.66it/s]
100%|██████████| 5124/5124 [00:40&lt;00:00, 126.19it/s]
100%|██████████| 5124/5124 [00:41&lt;00:00, 123.15it/s]
100%|██████████| 5124/5124 [00:42&lt;00:00, 121.05it/s]
100%|██████████| 5124/5124 [00:45&lt;00:00, 113.27it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Leadfield indices corresponding to localized sources: [31, 3557, 795, 1213, 1690, 2506, 2697, 2602, 1225, 83, 1966, 2085, 994, 2850, 2212, 4404, 4304, 4882, 608, 2522, 2325, 1876, 6, 3255, 1860, 3714, 4804, 2690, 84, 371, 2454, 3624, 5108, 1971, 265, 650, 992, 2727, 42, 4698, 329, 2574, 1258, 4002, 3368, 4920, 3, 33, 1405, 2887, 2333, 2771, 4604, 3333, 302, 306, 4422, 2597, 2580, 16, 4266, 3815]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Transform leadfield indices to vertices</span>
<span class="n">lh_vert_sen</span><span class="p">,</span> <span class="n">lh_idx_sen</span><span class="p">,</span> <span class="n">rh_vert_sen</span><span class="p">,</span> <span class="n">rh_idx_sen</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">transform_leadfield_indices_to_vertices</span><span class="p">(</span>
    <span class="n">lf_idx</span><span class="o">=</span><span class="n">locs_sen</span><span class="p">[</span><span class="s2">&quot;sources&quot;</span><span class="p">],</span>
    <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">,</span>
    <span class="n">hemi</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span>
    <span class="n">include_mapping</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">locs_sen</span><span class="o">.</span><span class="n">add_vertices_info</span><span class="p">(</span>
    <span class="n">lh_vertices</span><span class="o">=</span><span class="n">lh_vert_sen</span><span class="p">,</span>
    <span class="n">lh_indices</span><span class="o">=</span><span class="n">lh_idx_sen</span><span class="p">,</span>
    <span class="n">rh_vertices</span><span class="o">=</span><span class="n">rh_vert_sen</span><span class="p">,</span>
    <span class="n">rh_indices</span><span class="o">=</span><span class="n">rh_idx_sen</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Optionally, we can plot the localized sources on the brain surface:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># locs_sen.plot_localized_sources()</span>
</pre></div>
</div>
</div>
<p>Here, the size and color of the markers indicate the order of localization:</p>
<ul class="simple">
<li><p>large, red foci: sources localized earlier</p></li>
<li><p>small, white foci: sources localized later</p></li>
</ul>
</section>
<section id="Reconstruct">
<h3>Reconstruct<a class="headerlink" href="#Reconstruct" title="Link to this heading">#</a></h3>
<p>Now that we have localized sources of interest, the next sgtep is to <strong>reconstruct their activity</strong>. First, we restrict the original forward model to only include the localized sources. This reduces the forward solution to the relevant subspace:|</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Subset mne.Forward</span>
<span class="n">new_fwd_sen</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">subset_forward</span><span class="p">(</span>
    <span class="n">old_fwd</span><span class="o">=</span><span class="n">fwd</span><span class="p">,</span>
    <span class="n">localized</span><span class="o">=</span><span class="n">locs_sen</span><span class="p">,</span>
    <span class="n">hemi</span><span class="o">=</span><span class="s2">&quot;both&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>To compute the filters, we will use <code class="docutils literal notranslate"><span class="pre">beamformer.make_filter</span></code>.</p>
<p>This function works similarly to <code class="docutils literal notranslate"><span class="pre">mne.beamformer.make_lcmv</span></code>, but with additional parameters specific to MVPURE.</p>
<p>We provide these in a dictionary called <code class="docutils literal notranslate"><span class="pre">mvpure_params</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">filter_type</span></code>: type of the beamformer to use. Options are: <code class="docutils literal notranslate"><span class="pre">MVP_R</span></code> and <code class="docutils literal notranslate"><span class="pre">MVP_N</span></code>. In this case, we will use <code class="docutils literal notranslate"><span class="pre">MVP_R</span></code> as it is generalization of commonly used LCMV filter. -<code class="docutils literal notranslate"><span class="pre">filter_rank</span></code>: optimization rank parameter. For best performance, we use the same rank as in the localization step.</p></li>
</ul>
<p>Note: setting <code class="docutils literal notranslate"><span class="pre">filter_rank=&quot;ful&quot;</span></code> reduces the method to a standard LCMV filter. For theoretical details see [PAPER].</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># MVPURE filter parameters</span>
<span class="n">mvpure_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;filter_type&#39;</span><span class="p">:</span> <span class="s1">&#39;MVP_R&#39;</span><span class="p">,</span>
    <span class="s1">&#39;filter_rank&#39;</span><span class="p">:</span> <span class="n">sugg_rank</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build beamformer filter (similar to LCMV but with MVPURE options)</span>
<span class="n">filter_sen</span> <span class="o">=</span> <span class="n">beamformer</span><span class="o">.</span><span class="n">make_filter</span><span class="p">(</span>
    <span class="n">signal_sen</span><span class="o">.</span><span class="n">info</span><span class="p">,</span>
    <span class="n">new_fwd_sen</span><span class="p">,</span>
    <span class="n">data_cov_sen</span><span class="p">,</span>
    <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">noise_cov</span><span class="o">=</span><span class="n">noise_cov</span><span class="p">,</span>
    <span class="n">pick_ori</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># not needed with fixed orientation forward</span>
    <span class="n">weight_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mvpure_params</span><span class="o">=</span><span class="n">mvpure_params</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Computing rank from covariance with rank=None
    Using tolerance 4.4e-13 (2.2e-16 eps * 128 dim * 15  max singular value)
    Estimated rank (eeg): 86
    EEG: rank 86 computed from 128 data channels with 1 projector
Computing rank from covariance with rank=None
    Using tolerance 3.6e-13 (2.2e-16 eps * 128 dim * 13  max singular value)
    Estimated rank (eeg): 86
    EEG: rank 86 computed from 128 data channels with 1 projector
Making MVP_R beamformer with rank {&#39;eeg&#39;: 86} (note: MNE-Python rank)
Computing inverse operator with 128 channels.
    128 out of 128 channels remain after picking
Selected 128 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 1)
Computing rank from covariance with rank={&#39;eeg&#39;: 86}
    Setting small EEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 62 sources
MVP_R computation - in progress...
Filter rank: 42
Filter computation complete
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply filter to cropped evoked response</span>
<span class="n">stc_sen</span> <span class="o">=</span> <span class="n">beamformer</span><span class="o">.</span><span class="n">apply_filter</span><span class="p">(</span><span class="n">signal_sen</span><span class="p">,</span> <span class="n">filter_sen</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We then attach the resulting <code class="docutils literal notranslate"><span class="pre">mne.SourceEstimate</span></code> to the localized sources object, making it easier to visualize:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add reconstructed source time course</span>
<span class="n">locs_sen</span><span class="o">.</span><span class="n">add_stc</span><span class="p">(</span><span class="n">stc_sen</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Finally, let’s plot the localized sources with their reconstructed activity:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">viz</span><span class="o">.</span><span class="n">plot_sources_with_activity</span><span class="p">(</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">stc</span><span class="o">=</span><span class="n">stc_sen</span><span class="p">,</span>
    <span class="n">background</span><span class="o">=</span><span class="s2">&quot;white&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using control points [2.91332758e-09 3.43983961e-09 7.89233742e-09]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;mne.viz._brain._brain.Brain at 0x1583aa270&gt;
</pre></div></div>
</div>
</section>
</section>
<section id="%22Cognitive%22-task">
<h2>“Cognitive” task<a class="headerlink" href="#%22Cognitive%22-task" title="Link to this heading">#</a></h2>
<p>After examing the early sensory responses, we now turn to the later cognitive stahe of processing in the oddball paradigm. In EEG, target stimuli typically evoke a P300 component — a positive deflection peaking around 300–600 ms after stimulus onset. This response is thought to reflect higher-level cognitive processes, such as attention allocation and stimulus evaluation, in contrast to the earlier sensory responses.</p>
<p>For this dataset, we will therefore define the cognitive time window as <strong>350–600 ms</strong>. The pipeline remains the same as before:</p>
<ul class="simple">
<li><p>Compute noise covariance (always from −200 to 0 ms).</p></li>
<li><p>Compute data covariance in the cognitive window (350–600 ms).</p></li>
<li><p>Subset the evoked signal to this time range.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute data covariance for range corresponding to sensory processing</span>
<span class="n">data_cov_task</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span>
    <span class="n">sel_epoched</span><span class="p">,</span>
    <span class="n">tmin</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;empirical&quot;</span>
<span class="p">)</span>
<span class="c1"># There&#39;s no need to compute `noise_covariance` again as it is the same time interval</span>

<span class="n">sel_evoked</span> <span class="o">=</span> <span class="n">sel_epoched</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>

<span class="c1"># Subset signal for given time range</span>
<span class="n">signal_task</span> <span class="o">=</span> <span class="n">sel_evoked</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span>
    <span class="n">tmin</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mf">0.6</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
    Created an SSP operator (subspace dimension = 1)
    Setting small EEG eigenvalues to zero (without PCA)
Reducing data rank from 128 -&gt; 127
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 5070
[done]
</pre></div></div>
</div>
<p>From here, we can repeat the same steps as in the sensory section:</p>
<ul class="simple">
<li><p>analyze eigenvalues of <span class="math notranslate nohighlight">\(RN^{-1}\)</span>,</p></li>
<li><p>localize sources,</p></li>
<li><p>reconstruct signals with MVPURE filters,</p></li>
<li><p>and finally visualize the results.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Suggest number of sources to localize</span>
<span class="c1"># and optimization parameter to use for both localization and reconstruction</span>
<span class="n">sugg_n_sources</span><span class="p">,</span> <span class="n">sugg_rank</span> <span class="o">=</span> <span class="n">localizer</span><span class="o">.</span><span class="n">suggest_n_sources_and_rank</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span><span class="n">data_cov_task</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">N</span><span class="o">=</span><span class="n">noise_cov</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">show_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">14</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_source_localization_and_reconstruction_on_data_from_oddball_paradigm_31_0.png" src="../_images/tutorials_source_localization_and_reconstruction_on_data_from_oddball_paradigm_31_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Suggested number of sources to localize: 69
Suggested rank is: 50
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Localize</span>
<span class="n">locs_task</span> <span class="o">=</span> <span class="n">localizer</span><span class="o">.</span><span class="n">localize</span><span class="p">(</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">subjects_dir</span><span class="o">=</span><span class="n">subjects_dir</span><span class="p">,</span>
    <span class="n">localizer_to_use</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mpz_mvp&quot;</span><span class="p">],</span>
    <span class="n">n_sources_to_localize</span><span class="o">=</span><span class="n">sugg_n_sources</span><span class="p">,</span>
    <span class="n">R</span><span class="o">=</span><span class="n">data_cov_task</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">N</span><span class="o">=</span><span class="n">noise_cov</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">forward</span><span class="o">=</span><span class="n">fwd</span><span class="p">,</span>
    <span class="n">r</span><span class="o">=</span><span class="n">sugg_rank</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-cyan-fg">Calculating activity index for localizer: mpz_mvp</span>
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 5124/5124 [00:22&lt;00:00, 227.29it/s]
100%|██████████| 5124/5124 [00:23&lt;00:00, 219.92it/s]
100%|██████████| 5124/5124 [00:24&lt;00:00, 206.87it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 230.55it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 239.85it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 232.09it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 241.26it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 234.91it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 242.70it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.91it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 234.48it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 241.44it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 239.30it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 248.39it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 246.96it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.96it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 250.55it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 252.83it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 250.98it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 250.03it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 249.71it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 252.17it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 245.33it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 252.36it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 247.02it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 251.69it/s]
100%|██████████| 5124/5124 [00:23&lt;00:00, 215.61it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 234.60it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.44it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 245.63it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 240.35it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 247.86it/s]
100%|██████████| 5124/5124 [00:20&lt;00:00, 246.37it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.88it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.70it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 243.27it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 238.34it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 239.47it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 238.29it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 242.33it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 235.48it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 228.16it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 225.14it/s]
100%|██████████| 5124/5124 [00:21&lt;00:00, 233.82it/s]
100%|██████████| 5124/5124 [00:24&lt;00:00, 206.37it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 227.36it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 224.77it/s]
100%|██████████| 5124/5124 [00:27&lt;00:00, 185.77it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 226.67it/s]
100%|██████████| 5124/5124 [00:22&lt;00:00, 231.82it/s]
100%|██████████| 5124/5124 [00:30&lt;00:00, 165.56it/s]
100%|██████████| 5124/5124 [00:33&lt;00:00, 154.77it/s]
100%|██████████| 5124/5124 [00:31&lt;00:00, 163.60it/s]
100%|██████████| 5124/5124 [00:31&lt;00:00, 165.03it/s]
100%|██████████| 5124/5124 [00:31&lt;00:00, 162.19it/s]
100%|██████████| 5124/5124 [00:32&lt;00:00, 159.90it/s]
100%|██████████| 5124/5124 [00:33&lt;00:00, 154.72it/s]
100%|██████████| 5124/5124 [00:33&lt;00:00, 151.46it/s]
100%|██████████| 5124/5124 [00:34&lt;00:00, 148.82it/s]
100%|██████████| 5124/5124 [00:34&lt;00:00, 148.85it/s]
100%|██████████| 5124/5124 [00:35&lt;00:00, 142.92it/s]
100%|██████████| 5124/5124 [00:37&lt;00:00, 137.03it/s]
100%|██████████| 5124/5124 [00:39&lt;00:00, 128.70it/s]
100%|██████████| 5124/5124 [00:40&lt;00:00, 127.15it/s]
100%|██████████| 5124/5124 [00:41&lt;00:00, 123.43it/s]
100%|██████████| 5124/5124 [00:42&lt;00:00, 120.62it/s]
100%|██████████| 5124/5124 [00:42&lt;00:00, 120.70it/s]
100%|██████████| 5124/5124 [00:42&lt;00:00, 119.88it/s]
100%|██████████| 5124/5124 [00:43&lt;00:00, 117.34it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Leadfield indices corresponding to localized sources: [1689, 1291, 1489, 2159, 4405, 5051, 2039, 800, 2020, 3224, 1792, 4998, 821, 1865, 3762, 4165, 2372, 2471, 4817, 495, 1755, 2548, 3334, 1572, 2322, 2008, 4379, 3733, 4426, 2527, 2230, 2362, 4774, 356, 2545, 902, 108, 3720, 211, 481, 64, 2740, 2303, 4641, 148, 170, 1460, 3454, 68, 4850, 1732, 641, 2310, 4678, 764, 669, 1376, 3730, 2856, 4542, 4680, 2932, 3896, 600, 3172, 2564, 2631, 4982, 1342]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Transform leadfield indices to vertices</span>
<span class="n">lh_vert_task</span><span class="p">,</span> <span class="n">lh_idx_task</span><span class="p">,</span> <span class="n">rh_vert_task</span><span class="p">,</span> <span class="n">rh_idx_task</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">transform_leadfield_indices_to_vertices</span><span class="p">(</span>
    <span class="n">lf_idx</span><span class="o">=</span><span class="n">locs_task</span><span class="p">[</span><span class="s2">&quot;sources&quot;</span><span class="p">],</span>
    <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">,</span>
    <span class="n">hemi</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span>
    <span class="n">include_mapping</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">locs_task</span><span class="o">.</span><span class="n">add_vertices_info</span><span class="p">(</span>
    <span class="n">lh_vertices</span><span class="o">=</span><span class="n">lh_vert_task</span><span class="p">,</span>
    <span class="n">lh_indices</span><span class="o">=</span><span class="n">lh_idx_task</span><span class="p">,</span>
    <span class="n">rh_vertices</span><span class="o">=</span><span class="n">rh_vert_task</span><span class="p">,</span>
    <span class="n">rh_indices</span><span class="o">=</span><span class="n">rh_idx_task</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_fwd_task</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">subset_forward</span><span class="p">(</span>
    <span class="n">old_fwd</span><span class="o">=</span><span class="n">fwd</span><span class="p">,</span>
    <span class="n">localized</span><span class="o">=</span><span class="n">locs_task</span><span class="p">,</span>
    <span class="n">hemi</span><span class="o">=</span><span class="s2">&quot;both&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mcmv_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;filter_rank&#39;</span><span class="p">:</span> <span class="n">sugg_rank</span><span class="p">,</span>
    <span class="s2">&quot;filter_type&quot;</span><span class="p">:</span> <span class="s2">&quot;MVP_R&quot;</span>
<span class="p">}</span>

<span class="n">filter_task</span> <span class="o">=</span> <span class="n">beamformer</span><span class="o">.</span><span class="n">make_filter</span><span class="p">(</span>
    <span class="n">signal_task</span><span class="o">.</span><span class="n">info</span><span class="p">,</span>
    <span class="n">new_fwd_task</span><span class="p">,</span>
    <span class="n">data_cov_task</span><span class="p">,</span>
    <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">noise_cov</span><span class="o">=</span><span class="n">noise_cov</span><span class="p">,</span>
    <span class="n">pick_ori</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># because scalar forward</span>
    <span class="n">weight_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mvpure_params</span><span class="o">=</span><span class="n">mcmv_params</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Computing rank from covariance with rank=None
    Using tolerance 5.2e-13 (2.2e-16 eps * 128 dim * 18  max singular value)
    Estimated rank (eeg): 86
    EEG: rank 86 computed from 128 data channels with 1 projector
Computing rank from covariance with rank=None
    Using tolerance 3.6e-13 (2.2e-16 eps * 128 dim * 13  max singular value)
    Estimated rank (eeg): 86
    EEG: rank 86 computed from 128 data channels with 1 projector
Making MVP_R beamformer with rank {&#39;eeg&#39;: 86} (note: MNE-Python rank)
Computing inverse operator with 128 channels.
    128 out of 128 channels remain after picking
Selected 128 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 1)
Computing rank from covariance with rank={&#39;eeg&#39;: 86}
    Setting small EEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 69 sources
MVP_R computation - in progress...
Filter rank: 50
Filter computation complete
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stc_task</span> <span class="o">=</span> <span class="n">beamformer</span><span class="o">.</span><span class="n">apply_filter</span><span class="p">(</span><span class="n">signal_task</span><span class="p">,</span> <span class="n">filter_task</span><span class="p">)</span>

<span class="c1"># Add source estimate to mvpure_py.Localized object</span>
<span class="n">locs_task</span><span class="o">.</span><span class="n">add_stc</span><span class="p">(</span><span class="n">stc_task</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">viz</span><span class="o">.</span><span class="n">plot_sources_with_activity</span><span class="p">(</span>
    <span class="n">subject</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
    <span class="n">stc</span><span class="o">=</span><span class="n">stc_task</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using control points [2.84206626e-09 3.11743662e-09 5.08812233e-09]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;mne.viz._brain._brain.Brain at 0x16c554cd0&gt;
</pre></div></div>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="preprocessing_data_from_oddball%20paradigm.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">EEG Preprocessing for an Oddball Paradigm</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#%22Sensory%22-processing">“Sensory” processing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#RN^{-1}-eigenvalues-analysis"><span class="math notranslate nohighlight">\(RN^{-1}\)</span> eigenvalues analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Localize">Localize</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Reconstruct">Reconstruct</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#%22Cognitive%22-task">“Cognitive” task</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorials/source_localization_and_reconstruction_on_data_from_oddball_paradigm.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, Julia Jurkowska et al.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>